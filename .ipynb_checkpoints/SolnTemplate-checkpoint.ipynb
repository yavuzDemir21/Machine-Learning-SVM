{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>CMPE 462 - Project 2<br>Implementing an SVM Classifier<br>Due: May 18, 2020, 23:59</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Student ID1:** 2015400084\n",
    "* **Student ID2:** 2015400030\n",
    "* **Student ID3:** ALKIM NO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this project, you are going to implement SVM. For this purpose, a data set (data.mat) is given to you. You can load the mat dataset into Python using the function `loadmat` in `Scipy.io`. When you load the data, you will obtain a dictionary object, where `X` stores the data matrix and `Y` stores the labels. You can use the first 150 samples for training and the rest for testing. In this project, you will use the software package [`LIBSVM`](http://www.csie.ntu.edu.tw/~cjlin/libsvm/) to implement SVM. Note that `LIBSVM` has a [`Python interface`](https://github.com/cjlin1/libsvm/tree/master/python), so you can call the SVM functions in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Mon Nov 07 21:39:10 2011',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'Y': array([[ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1]], dtype=int16),\n",
       " 'X': array([[ 0.708333,  1.      ,  1.      , ...,  0.      ,  1.      ,\n",
       "         -1.      ],\n",
       "        [ 0.583333, -1.      ,  0.333333, ...,  0.      , -1.      ,\n",
       "          1.      ],\n",
       "        [ 0.166667,  1.      , -0.333333, ..., -1.      , -1.      ,\n",
       "          1.      ],\n",
       "        ...,\n",
       "        [ 0.125   , -1.      , -0.333333, ...,  0.      , -1.      ,\n",
       "         -1.      ],\n",
       "        [ 0.166667,  1.      ,  1.      , ...,  0.      , -1.      ,\n",
       "          0.5     ],\n",
       "        [ 0.583333,  1.      ,  1.      , ...,  0.      ,  1.      ,\n",
       "         -1.      ]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:150, :]\n",
    "X_test = X[150:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[0:150, 0]\n",
    "y_test = y[150:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install libsvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - 30 pts\n",
    "\n",
    "Train a hard margin linear SVM and report both train and test classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libsvm.svmutil import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_margin_linear_svm = svm_train(y_train, X_train, \"-t 0 -c 1e10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 58.6667% (88/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "# Train classification accuracy\n",
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, hard_margin_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 55.8333% (67/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "# Test classification accuracy\n",
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, hard_margin_linear_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - 40 pts\n",
    "\n",
    "Train soft margin SVM for different values of the parameter $C$, and with different kernel functions. Systematically report your results. For instance, report the performances of different kernels for a fixed $C$, then report the performance for different $C$ values for a fixed kernel, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_1_linear_svm = svm_train(y_train, X_train, \"-t 0 -c 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 89.3333% (134/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_1_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 85.8333% (103/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_1_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_10_linear_svm = svm_train(y_train, X_train, \"-t 0 -c 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.6667% (133/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_10_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86.6667% (104/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_10_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_100_linear_svm = svm_train(y_train, X_train, \"-t 0 -c 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88% (132/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_100_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 85.8333% (103/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_100_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_1000_linear_svm = svm_train(y_train, X_train, \"-t 0 -c 1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88% (132/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_1000_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 85.8333% (103/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_1000_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_polynomial_linear_svm = svm_train(y_train, X_train, \"-t 1 -c 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 84.6667% (127/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_polynomial_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 81.6667% (98/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_polynomial_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_radial_linear_svm = svm_train(y_train, X_train, \"-t 2 -c 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86% (129/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_radial_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 83.3333% (100/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_radial_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_sigmoid_linear_svm = svm_train(y_train, X_train, \"-t 3 -c 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 85.3333% (128/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_sigmoid_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 85.8333% (103/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_sigmoid_linear_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - 15 pts\n",
    "\n",
    "Please report how the number of support vectors changes as the value of $C$ increases (while all other parameters remain the same). Discuss whether your observations match the theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<svm.svm_model at 0x125f01830>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train(y_train, X_train, \"-t 0 -c 100\") # 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<svm.svm_model at 0x125cb3f80>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train(y_train, X_train, \"-t 0 -c 10\") # 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<svm.svm_model at 0x125d69830>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train(y_train, X_train, \"-t 0 -c 1\") # 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<svm.svm_model at 0x1259c3a70>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train(y_train, X_train, \"-t 0 -c 0.1\") # 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<svm.svm_model at 0x12602d560>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train(y_train, X_train, \"-t 0 -c 0.01\") # 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<svm.svm_model at 0x125cb3dd0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train(y_train, X_train, \"-t 0 -c 0.001\") # 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<svm.svm_model at 0x125e0e950>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train(y_train, X_train, \"-t 0 -c 0.0001\") # 140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C parameter tells the SVM optimization how much you want to avoid misclassifying each training example. For large values of C, the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly. Conversely, a very small value of C will cause the optimizer to look for a larger-margin separating hyperplane, even if that hyperplane misclassifies more points. For very tiny values of C, you should get misclassified examples, often even if your training data is linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - 15 pts\n",
    "\n",
    "Please investigate the changes in the hyperplane when you remove one of the support vectors, vs., one data point that is not a support vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 58\n",
    "soft_margin_removed_svm = svm_train(np.delete(y_train, 148, axis=0), np.delete(X_train, 148, axis=0), \"-t 0 -c 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 62\n",
    "soft_margin_removed_point = svm_train(np.delete(y_train, 0, axis=0), np.delete(X_train, 0, axis=0), \"-t 0 -c 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<svm.svm_model at 0x125cb35f0>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_margin_1_linear_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 7,\n",
       " 14,\n",
       " 38,\n",
       " 41,\n",
       " 45,\n",
       " 47,\n",
       " 48,\n",
       " 51,\n",
       " 57,\n",
       " 59,\n",
       " 62,\n",
       " 68,\n",
       " 70,\n",
       " 82,\n",
       " 83,\n",
       " 90,\n",
       " 92,\n",
       " 102,\n",
       " 106,\n",
       " 111,\n",
       " 113,\n",
       " 117,\n",
       " 122,\n",
       " 131,\n",
       " 132,\n",
       " 138,\n",
       " 145,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 20,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 27,\n",
       " 30,\n",
       " 32,\n",
       " 40,\n",
       " 44,\n",
       " 61,\n",
       " 67,\n",
       " 69,\n",
       " 75,\n",
       " 77,\n",
       " 85,\n",
       " 88,\n",
       " 97,\n",
       " 125,\n",
       " 129,\n",
       " 133,\n",
       " 135,\n",
       " 140,\n",
       " 142,\n",
       " 144]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_margin_1_linear_svm.get_sv_indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Task - 10 pts\n",
    "\n",
    "Use Python and [CVXOPT](http://cvxopt.org) QP solver to implement the hard margin SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
