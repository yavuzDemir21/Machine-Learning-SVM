{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>CMPE 462 - Project 2<br>Implementing an SVM Classifier<br>Due: May 18, 2020, 23:59</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Student ID1:** 2015400084\n",
    "* **Student ID2:** 2015400030\n",
    "* **Student ID3:** 2017400294"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this project, you are going to implement SVM. For this purpose, a data set (data.mat) is given to you. You can load the mat dataset into Python using the function `loadmat` in `Scipy.io`. When you load the data, you will obtain a dictionary object, where `X` stores the data matrix and `Y` stores the labels. You can use the first 150 samples for training and the rest for testing. In this project, you will use the software package [`LIBSVM`](http://www.csie.ntu.edu.tw/~cjlin/libsvm/) to implement SVM. Note that `LIBSVM` has a [`Python interface`](https://github.com/cjlin1/libsvm/tree/master/python), so you can call the SVM functions in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Mon Nov 07 21:39:10 2011',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'Y': array([[ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [ 1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [-1],\n",
       "        [ 1]], dtype=int16),\n",
       " 'X': array([[ 0.708333,  1.      ,  1.      , ...,  0.      ,  1.      ,\n",
       "         -1.      ],\n",
       "        [ 0.583333, -1.      ,  0.333333, ...,  0.      , -1.      ,\n",
       "          1.      ],\n",
       "        [ 0.166667,  1.      , -0.333333, ..., -1.      , -1.      ,\n",
       "          1.      ],\n",
       "        ...,\n",
       "        [ 0.125   , -1.      , -0.333333, ...,  0.      , -1.      ,\n",
       "         -1.      ],\n",
       "        [ 0.166667,  1.      ,  1.      , ...,  0.      , -1.      ,\n",
       "          0.5     ],\n",
       "        [ 0.583333,  1.      ,  1.      , ...,  0.      ,  1.      ,\n",
       "         -1.      ]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:150, :]\n",
    "X_test = X[150:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[0:150, 0]\n",
    "y_test = y[150:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install libsvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - 30 pts\n",
    "\n",
    "Train a hard margin linear SVM and report both train and test classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libsvm.svmutil import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_margin_linear_svm = svm_train(y_train, X_train, \"-t 0 -c 1e10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 74.6667% (112/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "# Train classification accuracy\n",
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, hard_margin_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 77.5% (93/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "# Test classification accuracy\n",
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, hard_margin_linear_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - 40 pts\n",
    "\n",
    "Train soft margin SVM for different values of the parameter $C$, and with different kernel functions. Systematically report your results. For instance, report the performances of different kernels for a fixed $C$, then report the performance for different $C$ values for a fixed kernel, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_1_linear_svm = svm_train(y_train, X_train, \"-t 0 -c 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86.6667% (130/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_1_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 85% (102/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_1_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_10_linear_svm = svm_train(y_train, X_train, \"-t 0 -c 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.6667% (133/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_10_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 81.6667% (98/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_10_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_100_linear_svm = svm_train(y_train, X_train, \"-t 0 -c 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.6667% (133/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_100_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 81.6667% (98/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_100_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_1000_linear_svm = svm_train(y_train, X_train, \"-t 0 -c 1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 90% (135/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_1000_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 81.6667% (98/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_1000_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_polynomial_linear_svm = svm_train(y_train, X_train, \"-t 1 -c 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86% (129/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_polynomial_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 82.5% (99/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_polynomial_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_radial_linear_svm = svm_train(y_train, X_train, \"-t 2 -c 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86.6667% (130/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_radial_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 84.1667% (101/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_radial_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_margin_sigmoid_linear_svm = svm_train(y_train, X_train, \"-t 3 -c 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 82.6667% (124/150) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_train, X_train, soft_margin_sigmoid_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 84.1667% (101/120) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, soft_margin_sigmoid_linear_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - 15 pts\n",
    "\n",
    "Please report how the number of support vectors changes as the value of $C$ increases (while all other parameters remain the same). Discuss whether your observations match the theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm_train(y_train, X_train, \"-t 0 -c 1000\").get_SV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm_train(y_train, X_train, \"-t 0 -c 500\").get_SV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm_train(y_train, X_train, \"-t 0 -c 100\").get_SV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm_train(y_train, X_train, \"-t 0 -c 10\").get_SV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm_train(y_train, X_train, \"-t 0 -c 1\").get_SV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm_train(y_train, X_train, \"-t 0 -c 0.1\").get_SV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm_train(y_train, X_train, \"-t 0 -c 0.01\").get_SV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm_train(y_train, X_train, \"-t 0 -c 0.001\").get_SV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm_train(y_train, X_train, \"-t 0 -c 0.0001\").get_SV())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C parameter tells the SVM optimization how much you want to avoid misclassifying each training example. For large values of C, the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly. Conversely, a very small value of C will cause the optimizer to look for a larger-margin separating hyperplane, even if that hyperplane misclassifies more points. For very tiny values of C, you should get misclassified examples, often even if your training data is linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - 15 pts\n",
    "\n",
    "Please investigate the changes in the hyperplane when you remove one of the support vectors, vs., one data point that is not a support vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(model):\n",
    "    matrix = []\n",
    "    for vector in model.get_SV():\n",
    "        vec = []\n",
    "        for i in range(1,14):\n",
    "            if i in vector:\n",
    "                vec.append(vector[i])\n",
    "            else:\n",
    "                vec.append(0)\n",
    "        matrix.append(vec)\n",
    "    matrix = np.array(matrix)\n",
    "    \n",
    "    vector = []\n",
    "    for val in model.get_sv_coef():\n",
    "        vector.append(val[0])\n",
    "    vector = np.array(vector)\n",
    "    \n",
    "    return np.dot(vector, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.47637751,  0.39813231,  0.86713369,  0.57366213,  0.32304567,\n",
       "        0.10008082,  0.05139059, -0.95512925,  0.07086555,  0.00576303,\n",
       "        0.24894908,  1.82218655,  0.5129991 ])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weights(soft_margin_1_linear_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1 = soft_margin_1_linear_svm.get_sv_indices()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 58\n",
    "soft_margin_removed_svm = svm_train(np.delete(y_train, ind1, axis=0), \\\n",
    "                        np.delete(X_train, ind1, axis=0), \"-t 0 -c 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.94880396e-01,  4.21184358e-01,  9.26642823e-01,  5.89842928e-01,\n",
       "        3.48248290e-01,  7.59411670e-02, -1.41871622e-03, -1.02161821e+00,\n",
       "        1.01050049e-01, -1.44539506e-01,  3.02006450e-01,  1.81590860e+00,\n",
       "        5.11221871e-01])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weights(soft_margin_removed_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_list =  [x for x in range(0,150)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2  = list(set(indice_list) - set(soft_margin_1_linear_svm.get_sv_indices()))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 62\n",
    "soft_margin_removed_point = svm_train(np.delete(y_train, ind2, axis=0), \\\n",
    "                                      np.delete(X_train, ind2, axis=0), \"-t 0 -c 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.47637751,  0.39813231,  0.86713369,  0.57366213,  0.32304567,\n",
       "        0.10008082,  0.05139059, -0.95512925,  0.07086555,  0.00576303,\n",
       "        0.24894908,  1.82218655,  0.5129991 ])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weights(soft_margin_removed_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a general kernel it is difficult to interpret the SVM weights, however for the linear SVM there actually is a useful interpretation:\n",
    "\n",
    "1) Recall that in linear SVM, the result is a hyperplane that separates the classes as best as possible. The weights represent this hyperplane, by giving you the coordinates of a vector which is orthogonal to the hyperplane - these are the coefficients given by svm.coef_. Let's call this vector w.\n",
    "\n",
    "2) What can we do with this vector? It's direction gives us the predicted class, so if you take the dot product of any point with the vector, you can tell on which side it is: if the dot product is positive, it belongs to the positive class, if it is negative it belongs to the negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Task - 10 pts\n",
    "\n",
    "Use Python and [CVXOPT](http://cvxopt.org) QP solver to implement the hard margin SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
